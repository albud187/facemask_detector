{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loops thru dataset files, turns each image into an array, classifies and returns list of arrays\n",
    "def img_array(path, class_num, size):\n",
    "    data =[]\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        new_array = cv2.resize(img_array, (size,size))\n",
    "        data.append(np.array([new_array, class_num]))\n",
    "    return(data)\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 120\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "#returns model prediction score for a single image\n",
    "\n",
    "def get_prediction(filepath, model):\n",
    "    tester = prepare(filepath)\n",
    "    tester = tester.astype(np.float32)/255\n",
    "    return(float(model.predict([tester])))\n",
    "\n",
    "#iterates thru images in a folder, returns list of model prediction scores for each image\n",
    "def mass_predict(path, model):\n",
    "    data =[]\n",
    "    for img in os.listdir(path):\n",
    "        #print(os.path.join(path,img))\n",
    "        prediction = get_prediction(os.path.join(path,img), model)\n",
    "        data.append(prediction)\n",
    "    return data\n",
    "\n",
    "#returns dataframe of images with their corresponding file names and model prediction scores\n",
    "def mass_predict_df(path,model):\n",
    "    df = pd.DataFrame(columns = ['filename', 'score'])\n",
    "    filenames = []\n",
    "    scores = []\n",
    "    for img in os.listdir(path):\n",
    "        #print(os.path.join(path,img))\n",
    "        prediction = get_prediction(os.path.join(path,img), model)\n",
    "        filenames.append(img)\n",
    "        scores.append(prediction)\n",
    "    df['filename'] = pd.Series(filenames)\n",
    "    df['score'] = pd.Series(scores)\n",
    "    return df\n",
    "\n",
    "#prepares image for input into model #watch filesize\n",
    "\n",
    "\n",
    "# gets class based on threshold score\n",
    "def verify(score, threshold):\n",
    "    if score >= threshold:\n",
    "        return('with_mask')\n",
    "    else:\n",
    "        return('without_mask')\n",
    "    \n",
    "# gets classed based on model prediction\n",
    "def get_class(filepath, model):\n",
    "    tester = prepare(filepath)\n",
    "    tester = tester.astype(np.float32)/255\n",
    "    return(float(model.predict_classes([tester])))\n",
    "\n",
    "# returns df of images with corresponding filenames and class   \n",
    "def mass_predict_df_class(path,model):\n",
    "    df = pd.DataFrame(columns = ['filename', 'score'])\n",
    "    filenames = []\n",
    "    scores = []\n",
    "    for img in os.listdir(path):\n",
    "        #print(os.path.join(path,img))\n",
    "        prediction = get_class(os.path.join(path,img), model)\n",
    "        filenames.append(img)\n",
    "        scores.append(prediction)\n",
    "    df['filename'] = pd.Series(filenames)\n",
    "    df['score'] = pd.Series(scores)\n",
    "    return df\n",
    "    \n",
    "def predict_and_show(filepath, model, threshold):\n",
    "    img = cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(verify(get_prediction(filepath, model), threshold))\n",
    "    print('score = ' + str(get_prediction(filepath, model)))\n",
    "    \n",
    "#evaluate df without mask\n",
    "def eval_df_without_mask(df_without_mask):\n",
    "    print('df without mask')\n",
    "    print(df_without_mask.describe())\n",
    "    stdev_over_mean1 =  float(df_without_mask.describe()[2:3]['score']) / float(df_without_mask.describe()[1:2]['score'])\n",
    "    print('stdev over mean = ' + str(stdev_over_mean1))\n",
    "    mean_plus_4_sigma1 = float(df_without_mask.describe()[1:2]['score']) + 4*float(df_without_mask.describe()[2:3]['score']) \n",
    "    mean_plus_3_sigma1 = float(df_without_mask.describe()[1:2]['score']) + 3*float(df_without_mask.describe()[2:3]['score'])\n",
    "    print('mean plus 4 sigma = ' + str(mean_plus_4_sigma1))\n",
    "    print('mean plus 3 sigma = ' + str(mean_plus_3_sigma1))\n",
    "\n",
    "#evaluate df with mask\n",
    "def eval_df_with_mask(df_with_mask):\n",
    "    print('df with mask')\n",
    "    print(df_with_mask.describe())\n",
    "    stdev_over_mean2 =  float(df_with_mask.describe()[2:3]['score']) / float(df_with_mask.describe()[1:2]['score'])\n",
    "    print('stdev over mean = ' + str(stdev_over_mean2))\n",
    "    mean_minus_4_sigma1 = float(df_with_mask.describe()[1:2]['score']) - 4*float(df_with_mask.describe()[2:3]['score']) \n",
    "    mean_minus_3_sigma1 = float(df_with_mask.describe()[1:2]['score']) - 3*float(df_with_mask.describe()[2:3]['score'])\n",
    "    print('mean minus 4 sigma = ' + str(mean_minus_4_sigma1))\n",
    "    print('mean minus 3 sigma = ' + str(mean_minus_3_sigma1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull dataset\n",
    "\n",
    "path_without_mask = 'dataset\\without_mask_3'\n",
    "class_num_without_mask = 0\n",
    "\n",
    "path_with_mask = 'dataset\\with_mask_4'\n",
    "class_num_with_mask = 1\n",
    "\n",
    "size = 120\n",
    "\n",
    "without_mask = img_array(path_without_mask, class_num_without_mask ,size)\n",
    "\n",
    "with_mask = img_array(path_with_mask, class_num_with_mask, size)\n",
    "\n",
    "data = without_mask + with_mask\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "scale_factor = 255\n",
    "for features, label in data:\n",
    "    X.append(features/scale_factor)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, size, size, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 5, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 120, 120, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1730 samples, validate on 577 samples\n",
      "Epoch 1/10\n",
      "1730/1730 [==============================] - 163s 94ms/sample - loss: 1.3892 - accuracy: 0.6237 - val_loss: 0.7341 - val_accuracy: 0.5771\n",
      "Epoch 2/10\n",
      "1730/1730 [==============================] - 142s 82ms/sample - loss: 0.5711 - accuracy: 0.7214 - val_loss: 0.7271 - val_accuracy: 0.5771\n",
      "Epoch 3/10\n",
      "1730/1730 [==============================] - 147s 85ms/sample - loss: 0.4103 - accuracy: 0.8208 - val_loss: 0.6179 - val_accuracy: 0.6170\n",
      "Epoch 4/10\n",
      "1730/1730 [==============================] - 144s 83ms/sample - loss: 0.3672 - accuracy: 0.8301 - val_loss: 0.6466 - val_accuracy: 0.6153\n",
      "Epoch 5/10\n",
      "1730/1730 [==============================] - 143s 83ms/sample - loss: 0.3382 - accuracy: 0.8514 - val_loss: 0.3046 - val_accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "1730/1730 [==============================] - 146s 85ms/sample - loss: 0.2478 - accuracy: 0.8902 - val_loss: 0.3096 - val_accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "1730/1730 [==============================] - 143s 83ms/sample - loss: 0.1803 - accuracy: 0.9266 - val_loss: 1.3114 - val_accuracy: 0.5789\n",
      "Epoch 8/10\n",
      "1730/1730 [==============================] - 147s 85ms/sample - loss: 0.1502 - accuracy: 0.9393 - val_loss: 0.1871 - val_accuracy: 0.9272\n",
      "Epoch 9/10\n",
      "1730/1730 [==============================] - 161s 93ms/sample - loss: 0.1235 - accuracy: 0.9549 - val_loss: 0.3015 - val_accuracy: 0.9012\n",
      "Epoch 10/10\n",
      "1730/1730 [==============================] - 165s 96ms/sample - loss: 0.1415 - accuracy: 0.9457 - val_loss: 0.2578 - val_accuracy: 0.9099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23eadc55390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build and train NN\n",
    "\n",
    "hyparam ={'loss':'binary_crossentropy',\n",
    "         'opt':'Adam',\n",
    "         'epochs': 10,\n",
    "         'batch_size':16,\n",
    "         'validation_data':(X_test, y_test) ,\n",
    "         'lr':0.001}\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#FC\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss= hyparam['loss'], optimizer = hyparam['opt'], metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = hyparam['batch_size'], epochs = hyparam['epochs'], validation_data = hyparam['validation_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0614 17:53:19.970312 17368 deprecation.py:506] From c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model.save('2020-06-14-1746-Conv2D.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1730 samples, validate on 577 samples\n",
      "Epoch 1/10\n",
      "1730/1730 [==============================] - 181s 105ms/sample - loss: 0.7179 - accuracy: 0.5838 - val_loss: 0.6643 - val_accuracy: 0.6014\n",
      "Epoch 2/10\n",
      "1730/1730 [==============================] - 171s 99ms/sample - loss: 0.6140 - accuracy: 0.6682 - val_loss: 0.5806 - val_accuracy: 0.7002\n",
      "Epoch 3/10\n",
      "1730/1730 [==============================] - 205s 118ms/sample - loss: 0.5174 - accuracy: 0.7543 - val_loss: 0.4142 - val_accuracy: 0.8232\n",
      "Epoch 4/10\n",
      "1730/1730 [==============================] - 198s 115ms/sample - loss: 0.4023 - accuracy: 0.8145 - val_loss: 0.8893 - val_accuracy: 0.6690\n",
      "Epoch 5/10\n",
      "1730/1730 [==============================] - 198s 115ms/sample - loss: 0.3766 - accuracy: 0.8370 - val_loss: 0.3756 - val_accuracy: 0.8544\n",
      "Epoch 6/10\n",
      "1730/1730 [==============================] - 181s 105ms/sample - loss: 0.3108 - accuracy: 0.8763 - val_loss: 0.3462 - val_accuracy: 0.8648\n",
      "Epoch 7/10\n",
      "1730/1730 [==============================] - 179s 103ms/sample - loss: 0.2702 - accuracy: 0.8902 - val_loss: 0.2938 - val_accuracy: 0.8908\n",
      "Epoch 8/10\n",
      "1730/1730 [==============================] - 159s 92ms/sample - loss: 0.2625 - accuracy: 0.8913 - val_loss: 0.2603 - val_accuracy: 0.8943\n",
      "Epoch 9/10\n",
      "1730/1730 [==============================] - 187s 108ms/sample - loss: 0.2268 - accuracy: 0.9092 - val_loss: 0.2941 - val_accuracy: 0.8839\n",
      "Epoch 10/10\n",
      "1730/1730 [==============================] - 181s 105ms/sample - loss: 0.2180 - accuracy: 0.9052 - val_loss: 0.2389 - val_accuracy: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e88e35320>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build and train NN\n",
    "\n",
    "hyparam ={'loss':'binary_crossentropy',\n",
    "         'opt':'Adam',\n",
    "         'epochs': 10,\n",
    "         'batch_size':16,\n",
    "         'validation_data':(X_test, y_test) ,\n",
    "         'lr':0.001}\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Conv\n",
    "model.add(Conv2D(128, (4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#FC\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss= hyparam['loss'], optimizer = hyparam['opt'], metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = hyparam['batch_size'], epochs = hyparam['epochs'], validation_data = hyparam['validation_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('2020-06-14-1901-Conv2D.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = hyparam['epochs']\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df without mask\n",
      "           score\n",
      "count  23.000000\n",
      "mean    0.182221\n",
      "std     0.274361\n",
      "min     0.002798\n",
      "25%     0.015135\n",
      "50%     0.058404\n",
      "75%     0.241696\n",
      "max     0.979985\n",
      "stdev over mean = 1.5056509213717384\n",
      "mean plus 4 sigma = 1.2796626875954613\n",
      "mean plus 3 sigma = 1.0053021525413548\n",
      "\n",
      "\n",
      "df with mask\n",
      "           score\n",
      "count  25.000000\n",
      "mean    0.672123\n",
      "std     0.369939\n",
      "min     0.032993\n",
      "25%     0.313006\n",
      "50%     0.822388\n",
      "75%     0.972811\n",
      "max     0.999988\n",
      "stdev over mean = 0.5504032687341355\n",
      "mean minus 4 sigma = -0.8076320668070385\n",
      "mean minus 3 sigma = -0.43769324142551946\n",
      "\n",
      "\n",
      "normalized mean difference = 0.5734257070811869\n"
     ]
    }
   ],
   "source": [
    "# model evaluation on devset\n",
    "#path1 is without mask, path2 is with mask\n",
    "\n",
    "path1 = 'dev_set\\without'\n",
    "path2 = 'dev_set\\with'\n",
    "model = tf.keras.models.load_model('2020-06-14-1833-Conv2D.model')\n",
    "\n",
    "df_without_mask = mass_predict_df(path1, model)\n",
    "df_with_mask = mass_predict_df(path2, model)\n",
    "\n",
    "eval_df_without_mask(df_without_mask)\n",
    "print('\\n')\n",
    "eval_df_with_mask(df_with_mask)\n",
    "\n",
    "print('\\n')\n",
    "x = (float(df_with_mask.describe()[1:2]['score'])-float(df_without_mask.describe()[1:2]['score'])) / (float(df_with_mask.describe()[1:2]['score'])+float(df_without_mask.describe()[1:2]['score']))\n",
    "print('normalized mean difference = ' +  str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.458258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "count  25.000000\n",
       "mean    0.720000\n",
       "std     0.458258\n",
       "min     0.000000\n",
       "25%     0.000000\n",
       "50%     1.000000\n",
       "75%     1.000000\n",
       "max     1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_predict_df_class(path2,model).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>with_test8.JPG</td>\n",
       "      <td>0.032993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>with_test18.JPG</td>\n",
       "      <td>0.035044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>with_test23.JPG</td>\n",
       "      <td>0.037733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>with_test17.JPG</td>\n",
       "      <td>0.041630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>with_test16.JPG</td>\n",
       "      <td>0.148572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>with_test33.JPG</td>\n",
       "      <td>0.281309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>with_test30.JPG</td>\n",
       "      <td>0.313006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>with_test3.JPG</td>\n",
       "      <td>0.522184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>with_test25.JPG</td>\n",
       "      <td>0.712699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>with_test26.JPG</td>\n",
       "      <td>0.735429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>with_test2.JPG</td>\n",
       "      <td>0.759676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>with_test21.JPG</td>\n",
       "      <td>0.797893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>with_test32.JPG</td>\n",
       "      <td>0.822388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>with_test19.JPG</td>\n",
       "      <td>0.845109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>with_test6.JPG</td>\n",
       "      <td>0.914994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>with_test11.JPG</td>\n",
       "      <td>0.955761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>with_test20.JPG</td>\n",
       "      <td>0.964874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>with_test27.JPG</td>\n",
       "      <td>0.969481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>with_test5.JPG</td>\n",
       "      <td>0.972811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>with_test24.JPG</td>\n",
       "      <td>0.980804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>with_test12.JPG</td>\n",
       "      <td>0.981057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>with_test14.JPG</td>\n",
       "      <td>0.988663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>with_test13.JPG</td>\n",
       "      <td>0.991174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>with_test31.JPG</td>\n",
       "      <td>0.997805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>with_test10.JPG</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename     score\n",
       "24   with_test8.JPG  0.032993\n",
       "7   with_test18.JPG  0.035044\n",
       "12  with_test23.JPG  0.037733\n",
       "6   with_test17.JPG  0.041630\n",
       "5   with_test16.JPG  0.148572\n",
       "21  with_test33.JPG  0.281309\n",
       "18  with_test30.JPG  0.313006\n",
       "17   with_test3.JPG  0.522184\n",
       "14  with_test25.JPG  0.712699\n",
       "15  with_test26.JPG  0.735429\n",
       "9    with_test2.JPG  0.759676\n",
       "11  with_test21.JPG  0.797893\n",
       "20  with_test32.JPG  0.822388\n",
       "8   with_test19.JPG  0.845109\n",
       "23   with_test6.JPG  0.914994\n",
       "1   with_test11.JPG  0.955761\n",
       "10  with_test20.JPG  0.964874\n",
       "16  with_test27.JPG  0.969481\n",
       "22   with_test5.JPG  0.972811\n",
       "13  with_test24.JPG  0.980804\n",
       "2   with_test12.JPG  0.981057\n",
       "4   with_test14.JPG  0.988663\n",
       "3   with_test13.JPG  0.991174\n",
       "19  with_test31.JPG  0.997805\n",
       "0   with_test10.JPG  0.999988"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_predict_df(path2,model).sort_values(by= 'score',ascending =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>without_test16.JPG</td>\n",
       "      <td>0.979985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>without_test8.JPG</td>\n",
       "      <td>0.893113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>without_test14.JPG</td>\n",
       "      <td>0.437251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>without_test13.JPG</td>\n",
       "      <td>0.377881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>without_test2.JPG</td>\n",
       "      <td>0.375466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>without_test12.JPG</td>\n",
       "      <td>0.346122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>without_test3.JPG</td>\n",
       "      <td>0.137270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>without_test20.JPG</td>\n",
       "      <td>0.109169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>without_test22.JPG</td>\n",
       "      <td>0.100456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>without_test15.JPG</td>\n",
       "      <td>0.091664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>without_test6.JPG</td>\n",
       "      <td>0.084915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>without_test23.JPG</td>\n",
       "      <td>0.058404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>without_test4.JPG</td>\n",
       "      <td>0.051999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>without_test1.JPG</td>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>without_test11.JPG</td>\n",
       "      <td>0.026586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>without_test18.JPG</td>\n",
       "      <td>0.022929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>without_test5.JPG</td>\n",
       "      <td>0.015955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>without_test21.JPG</td>\n",
       "      <td>0.014316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>without_test7.JPG</td>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>without_test9.JPG</td>\n",
       "      <td>0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>without_test19.JPG</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>without_test17.JPG</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>without_test10.JPG</td>\n",
       "      <td>0.002798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename     score\n",
       "7   without_test16.JPG  0.979985\n",
       "21   without_test8.JPG  0.893113\n",
       "5   without_test14.JPG  0.437251\n",
       "4   without_test13.JPG  0.377881\n",
       "11   without_test2.JPG  0.375466\n",
       "3   without_test12.JPG  0.346122\n",
       "16   without_test3.JPG  0.137270\n",
       "12  without_test20.JPG  0.109169\n",
       "14  without_test22.JPG  0.100456\n",
       "6   without_test15.JPG  0.091664\n",
       "19   without_test6.JPG  0.084915\n",
       "15  without_test23.JPG  0.058404\n",
       "17   without_test4.JPG  0.051999\n",
       "0    without_test1.JPG  0.051136\n",
       "2   without_test11.JPG  0.026586\n",
       "9   without_test18.JPG  0.022929\n",
       "18   without_test5.JPG  0.015955\n",
       "13  without_test21.JPG  0.014316\n",
       "20   without_test7.JPG  0.003920\n",
       "22   without_test9.JPG  0.003395\n",
       "10  without_test19.JPG  0.003352\n",
       "8   without_test17.JPG  0.002991\n",
       "1   without_test10.JPG  0.002798"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path1 is without\n",
    "#model = tf.keras.models.load_model('2020-06-06-0001-Conv2D.model')\n",
    "mass_predict_df(path1,model).sort_values(by= 'score',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
